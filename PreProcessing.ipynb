{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the libraries\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import spellchecker\n",
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('New_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '\n",
    "for i in range(len(df['Semi_cleaned_text'])):\n",
    "    text = text + ' ' + df['Semi_cleaned_text'][i]\n",
    "words = list(set(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant\n",
    "Eng_dict = enchant.Dict(\"en_US\")\n",
    "Corpus_words= words\n",
    "Checked_Word_List=[]\n",
    "UnChecked_Word_List=[]\n",
    "for word in Corpus_words:\n",
    "    if Eng_dict.check(word)==True:\n",
    "        Checked_Word_List.append(word)\n",
    "    else:\n",
    "        UnChecked_Word_List.append(word)\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "misspelled = spell.unknown(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dic = {\n",
    "    'fuk':'fuck',\n",
    "    'af':'as fuck',\n",
    "    'asf':'as fuck',\n",
    "    'n': 'and',\n",
    "    'tom':'from',\n",
    "    'wite': 'white',\n",
    "    'kenned':'ken',\n",
    "    'pedo': 'pedofile',\n",
    "    'vel':' ',\n",
    "    'aaf':' ',\n",
    "    'jou': 'so you',\n",
    "    'adhd': 'attention-deficit hyperactivity disorder',\n",
    "    'conf': 'confused',\n",
    "    'idler':'hitler',\n",
    "    'nti': 'attention',\n",
    "    'tric':'tricare',\n",
    "    'znd':'second',\n",
    "    'congressed':'congress',\n",
    "    'clhwitz': 'auschwitz',\n",
    "    'colo':'colorized',\n",
    "    'pend':'happened',\n",
    "    'lem':'them',\n",
    "    'tel':'tell',\n",
    "    'cams':'canada',\n",
    "    'aya in':'again',\n",
    "    'whited':'white',\n",
    "    'cuter':'cute',\n",
    "    'irk' : 'irritate',\n",
    "    'tran':'tranny',\n",
    "    'rehab': 'rehabilitation',\n",
    "    'wi hens': 'when',\n",
    "    'imma':'i am going to',\n",
    "    'eww':'disgust',\n",
    "    'tromp':'trump',\n",
    "    'oof':'extreme pain',\n",
    "    'cuck':'cock',\n",
    "    'meathead':'stupid',\n",
    "    'hornier':'horny',\n",
    "    'quran':'quran',\n",
    "    'bruh':'bro',\n",
    "    'poops':'poop',\n",
    "    'burqa':'burqa',\n",
    "    'dumpster':'dumpster',\n",
    "    'chemo':'chemo therapy',\n",
    "    'rofl':'roll on the floor laughing',\n",
    "    'isl':'islam',\n",
    "    'nyt':'new york times',\n",
    "    'trons':'trans',\n",
    "    'fwd':'forward',\n",
    "    'whies':'whites',\n",
    "    'iynch':'lynch',\n",
    "    'dumber':'dumb',\n",
    "    'olla':'alla',\n",
    "    'tts':'tits',\n",
    "    'uive':'give',\n",
    "    'muh':'much',\n",
    "    'yolo':'you only live once',\n",
    "    'ghns':'guns',\n",
    "    'paie':'paid',\n",
    "    'qum':'cum',\n",
    "    'cuter':'cute',\n",
    "    'jaly':'july',\n",
    "    'kool':'cool',\n",
    "    'wite':'white',\n",
    "    'arb':'arab',\n",
    "    'uld':'old',\n",
    "    'vagine':'vagina',\n",
    "    'fah':'far',\n",
    "    'gayest':'gay',\n",
    "    'uty':'duty',\n",
    "    'wyo':'who',\n",
    "    'ery':'very',\n",
    "    'yot':'you',\n",
    "    'nte':'note',\n",
    "    'raci':'race',\n",
    "    'ilh':'i will',\n",
    "    'mlk':'milk',\n",
    "    'bruhh':'bro',\n",
    "    'tney':'they',\n",
    "    'mussing':'missing',\n",
    "    'frt':'fart'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    temp = text.split() \n",
    "    res = [] \n",
    "    for wrd in temp: \n",
    "        res.append(custom_dic.get(wrd, wrd)) \n",
    "    res = ' '.join(res) \n",
    "    return str(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-172-2c3d01488ecc>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Semi_cleaned_text'][i] = expand_contractions(df['Semi_cleaned_text'][i])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(df)):\n",
    "    df['Semi_cleaned_text'][i] = expand_contractions(df['Semi_cleaned_text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_dataframe.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
